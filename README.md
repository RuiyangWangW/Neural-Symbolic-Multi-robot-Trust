# Neural-Symbolic Multi-Robot Trust System ğŸ¤–

**A Graph Neural Network framework for distributed trust assessment in multi-robot systems, comparing supervised GNN predictions against a symbolic baseline algorithm.**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸ¯ What This Does

This system addresses a critical challenge in multi-robot collaboration: **How do robots determine which teammates to trust when some may be adversarial?**

We compare two approaches:
1. **Paper Algorithm** (Symbolic Baseline): Rule-based trust updates using detection agreements and contradictions
2. **Supervised GNN** (Our Method): Graph Neural Network that learns trust patterns from graph structure

### Key Innovation: Structure-Only Learning

The GNN learns to detect adversarial behavior using **only graph topology** - no numerical features like positions or velocities. It learns from:
- Which robots detect which objects
- Which robots agree (co-detection edges)
- Which robots disagree (contradicts edges)
- The pattern of connections in the local graph

This makes the system:
- âœ… **Privacy-preserving**: No sensitive data shared
- âœ… **Robust**: Works even when adversaries manipulate detections
- âœ… **Generalizable**: Transfers to different environments and scenarios

---

## ğŸš€ Quick Start

### Installation

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install torch torch-geometric numpy matplotlib scikit-learn
```

### Complete Pipeline

```bash
# 1. Generate training dataset (8-12 hours, ~1.8M samples)
python generate_supervised_data.py \
  --episodes 15000 \
  --steps 200 \
  --step-interval 5 \
  --robot-density 0.0010,0.0015 \
  --output supervised_trust_dataset.pkl

# 2. Train supervised GNN model (2-4 hours)
python train_supervised_trust.py \
  --data supervised_trust_dataset.pkl \
  --epochs 1000 \
  --batch-size 32 \
  --lr 1e-3 \
  --patience 100 \
  --device auto

# 3. Compare Paper vs Supervised across 3 scenarios
python compare_trust_methods.py

# Output: Comparison plots and metrics showing which method works better!
```

---

## ğŸ“Š System Overview

### The Problem

In multi-robot teams performing collaborative tasks (search, surveillance, mapping), robots share object detections. But what if some robots are adversarial?

**Adversarial Behavior:**
- Report false positive objects (things that don't exist)
- Miss detections (false negatives)
- Deliberately provide misleading information

**Challenge:** Detect adversarial robots using only observation patterns, not ground truth.

### Our Solution: Two Approaches

#### 1. Paper Algorithm (Symbolic Baseline)

A rule-based trust update system:
- Increases trust when robots agree on detections (co-detection)
- Decreases trust when robots contradict each other
- Uses Beta distribution to track trust: Ï„ = Î±/(Î±+Î²)

**Pros:**
- Interpretable rules
- No training required
- Fast inference

**Cons:**
- Fixed rules don't adapt
- May miss complex deception patterns
- Sensitive to parameter tuning

#### 2. Supervised GNN (Our Method)

A Graph Neural Network trained on simulation data:
- Learns which graph patterns indicate adversarial behavior
- Adapts to different deception strategies
- Uses heterogeneous graph structure (6 edge types)

**Pros:**
- Learns complex patterns
- Adapts to data
- Better generalization

**Cons:**
- Requires training data
- Needs GPU for training
- Less interpretable

---

## ğŸ—ï¸ Architecture

### Supervised GNN Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Ego-Centric Graph                                 â”‚
â”‚   â€¢ Agent nodes: Nearby robots (5-15)                    â”‚
â”‚   â€¢ Track nodes: Detected objects (10-40)                â”‚
â”‚   â€¢ Edges: 6 relation types (co_detection, contradicts,  â”‚
â”‚     in_fov_and_observed, in_fov_only, etc.)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRIPLET ENCODER (Transformer-based)                      â”‚
â”‚   For each node, encode local edge patterns:             â”‚
â”‚   â€¢ Extract triplets: (src_type, relation, dst_type)     â”‚
â”‚   â€¢ Embed to 128-dim with 2-layer Transformer            â”‚
â”‚   â€¢ Output: Initial node embeddings with structural info â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HETEROGENEOUS GAT (3 layers, 4 attention heads)          â”‚
â”‚   Message passing across 6 edge types:                   â”‚
â”‚   â€¢ Learn from neighborhood structure                    â”‚
â”‚   â€¢ Aggregate evidence from connected nodes              â”‚
â”‚   â€¢ Build trust predictions from graph patterns          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: Trust Scores                                     â”‚
â”‚   â€¢ Ego robot trust: [0, 1] (1 = trustworthy)           â”‚
â”‚   â€¢ Track trust: [0, 1] for each detected object        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Statistics

- **Parameters**: 2,076,930 total
  - Triplet Encoders: 854,016 params (2 encoders)
  - GAT Layers: 1,200,384 params (3 layers)
  - Classifiers: 20,994 params
  - BatchNorm: 1,536 params
- **Hidden Dimension**: 128
- **Architecture**: PyTorch Geometric HeteroData + HeteroGATConv
- **Training Time**: ~2-4 hours on GPU (NVIDIA RTX 3090)
- **Inference Time**: ~5-10ms per ego-graph on CPU

### What Makes This Work

#### 1. **Symbolic Structure Encoding**

Instead of zero-initialized embeddings, nodes start with **Transformer-encoded symbolic triplets**:

```python
# For a robot node with 3 edges:
triplets = [
    (agent, co_detection, agent),      # Agrees with another robot
    (agent, contradicts, agent),       # Disagrees with another robot
    (agent, in_fov_and_observed, track) # Detects an object
]

# Encode as 8-dim vectors: (src_type[1], relation[6], dst_type[1])
# Feed through Transformer â†’ 128-dim embedding
```

This gives nodes **semantically meaningful starting points** before message passing.

#### 2. **Cross-Validation Constraints**

Trust updates require **multiple observations** to prevent single-robot manipulation:

**For Ego Robot:**
- Must have co_detection OR contradicts edges with other robots
- Without cross-validation: No trust update

**For Tracks (Objects):**
- Must be detected by ego robot
- Must have edges to â‰¥2 robots
- Without cross-validation: No trust update

**Why This Matters:**
- âœ… Prevents premature trust updates
- âœ… Requires consensus from multiple robots
- âœ… Exposes contradictions between robots
- âœ… Makes deception harder

#### 3. **Ego-Centric Design**

Each robot builds its own **local graph** within communication range:

```
Robot 5 builds graph:
  Agents: [Robot 5 (ego), Robot 2, Robot 7, Robot 9]
  Tracks: [Object A, Object B, Object C, ...]
  Edges: Only within this local view
```

**Benefits:**
- Scalable: O(N) graphs instead of O(NÂ²)
- Distributed: Each robot operates independently
- Privacy-preserving: No global knowledge required
- Realistic: Matches real-world communication limits

---

## ğŸ“ˆ How It Works

### 1. Simulation Environment

Multi-robot team in 100Ã—100m world:
- **Robots**: 5-15 robots, some adversarial (10-30%)
- **Objects**: 10-40 ground truth objects to detect
- **False Positives**: Adversarial robots report fake objects
- **False Negatives**: Robots miss real detections
- **Communication**: Robots share observations within 50m range

### 2. Graph Construction

For each robot at each timestep:

```python
# Build ego-centric graph
ego_graph = build_ego_graph(ego_robot, nearby_robots)

# Nodes:
#   - Agent nodes: ego + nearby robots
#   - Track nodes: all detected objects (after fusion)

# Edges (6 types):
#   - (agent, co_detection, agent): Robots detect same object
#   - (agent, contradicts, agent): One sees, other doesn't
#   - (agent, in_fov_and_observed, track): Robot detects object
#   - (agent, in_fov_only, track): Object in FoV but not detected
#   - Reverse edges for each
```

### 3. Trust Prediction

#### Paper Algorithm:

```python
for each timestep:
    # Check for agreements and contradictions
    agreements = count_co_detections(ego_robot, other_robots)
    contradictions = count_contradicts(ego_robot, other_robots)

    # Update trust (Beta distribution)
    if agreements > contradictions:
        Î± += agreement_weight
    else:
        Î² += contradiction_weight

    trust = Î± / (Î± + Î²)
```

#### Supervised GNN:

```python
for each timestep:
    # Build ego-graph
    ego_graph = build_graph(ego_robot, nearby_robots)

    # Check cross-validation
    if not has_cross_validation(ego_graph):
        continue  # Skip update

    # GNN prediction
    predictions = gnn_model(ego_graph)

    # Extract trust scores
    ego_trust = predictions['agent'][0]  # Ego robot
    track_trust = predictions['track'][meaningful_indices]

    # Update trust values
    update_trust(ego_robot, ego_trust)
    update_track_trust(tracks, track_trust)
```

### 4. Comparison

We run **identical simulations** with both methods and compare:
- Final trust values for legitimate vs adversarial robots
- Convergence speed
- Robustness to different FP/FN rates
- Classification accuracy

---

## ğŸ“ Training Process

### Dataset Generation

**What We Generate:**
- 15,000 episodes Ã— 40 sampled timesteps Ã— ~12 robots
- = ~1,800,000 ego-graphs (after cross-validation filtering)
- Each ego-graph is a training sample with labels

**Diversity:**
- Robot density: 0.001-0.0015 (5-15 robots per episode)
- Target density: 0.001-0.004 (10-40 objects)
- Adversarial ratio: 0.1-0.3 (10-30% adversarial robots)
- False positive rate: 0.1-0.3 (varies per episode)
- False negative rate: 0.0-0.3 (varies per episode)

**Cross-Validation Filtering:**
```
Before filtering: ~7,200,000 potential samples
After filtering: ~1,800,000 samples (25% pass rate)

Removed:
  â€¢ ~60%: Ego robot has no cross-validation
  â€¢ ~15%: No meaningful tracks (all isolated)
```

**Command:**
```bash
python generate_supervised_data.py \
  --episodes 15000 \
  --steps 200 \
  --step-interval 5 \
  --robot-density 0.0010,0.0015 \
  --output supervised_trust_dataset.pkl
```

### Model Training

**Configuration:**
- Loss: Binary cross-entropy (BCELoss)
- Optimizer: AdamW (lr=1e-3, weight_decay=1e-4)
- Scheduler: ReduceLROnPlateau (factor=0.7, patience=10)
- Batch Size: 32 graphs per batch
- Early Stopping: 100 epochs patience

**Performance Optimizations:**
- **PyG Batching**: Concatenates graphs for parallel processing (2-3Ã— faster)
- **Pre-computed Triplets**: Stored with dataset (1.49Ã— faster)
- **Combined**: ~4-5Ã— faster than naive implementation

**Expected Results:**
```
Epoch 100: Train Loss: 0.245, Val Loss: 0.267
           Train Acc: 87.3%, Val Acc: 85.1%

Epoch 200: Train Loss: 0.198, Val Loss: 0.221
           Train Acc: 91.2%, Val Acc: 88.7%

Final:     Train Acc: 93.1%, Val Acc: 90.2%
           F1 Score: 0.89 (agents), 0.88 (tracks)
```

**Command:**
```bash
python train_supervised_trust.py \
  --data supervised_trust_dataset.pkl \
  --epochs 1000 \
  --batch-size 32 \
  --lr 1e-3 \
  --patience 100 \
  --device auto
```

---

## ğŸ”¬ Evaluation

### Three Test Scenarios

We compare Paper vs Supervised on:

| Scenario | FP Rate | FN Rate | Challenge |
|----------|---------|---------|-----------|
| **Scenario 1**: Low FP, Low FN | 0.3 | 0.1 | Baseline conditions |
| **Scenario 2**: High FP, Low FN | 0.8 | 0.1 | Many false alarms |
| **Scenario 3**: Low FP, High FN | 0.3 | 0.3 | Many missed detections |

**Configuration:**
- 10 robots (30% adversarial)
- 20 ground truth objects
- 100 timesteps
- 100Ã—100m world

### Example Results

```
======================================================================
ğŸ¯ THREE SCENARIO COMPARISON SUMMARY
======================================================================

ğŸ“Š Performance Summary:
Scenario Name               | FP Rate | FN Rate | Leg (P/S)      | Adv (P/S)      | S-P Î”
--------------------------------------------------------------------------------------
Scenario_1_Low_FP_Low_FN   | 0.3     | 0.1     | 0.895/0.912 | 0.647/0.423 | +0.032
Scenario_2_High_FP_Low_FN  | 0.8     | 0.1     | 0.867/0.884 | 0.458/0.289 | +0.048
Scenario_3_Low_FP_High_FN  | 0.3     | 0.3     | 0.873/0.891 | 0.635/0.412 | +0.041
--------------------------------------------------------------------------------------
AVERAGE                    |         |         | 0.878/0.896 | 0.580/0.375 | +0.040

Legend:
  Leg (P/S) = Legitimate robot trust (Paper/Supervised)
  Adv (P/S) = Adversarial robot trust (Paper/Supervised)
  S-P Î” = Supervised minus Paper difference

ğŸ” Key Findings:
   â€¢ Paper Algorithm:
     - Legitimate: 0.878
     - Adversarial: 0.580
     - Gap: +0.298
   â€¢ Supervised Model:
     - Legitimate: 0.896
     - Adversarial: 0.375
     - Gap: +0.521  â­ BETTER SEPARATION!
   â€¢ Average Supervised vs Paper Difference: +0.040
```

### What This Means

**Supervised GNN Advantages:**
- âœ… **Better adversarial detection**: Lower trust for adversarial robots (0.375 vs 0.580)
- âœ… **Higher legitimate trust**: Maintains trust in good robots (0.896 vs 0.878)
- âœ… **Clearer separation**: Gap of 0.521 vs 0.298 (75% improvement!)
- âœ… **More robust**: Works across different FP/FN scenarios

**When to Use Each:**
- **Paper Algorithm**: When interpretability matters, no training data available
- **Supervised GNN**: When performance is critical, training data available

---

## ğŸ“ File Structure

### Core Implementation

```
Neural-Symbolic-Multi-robot-Trust/
â”‚
â”œâ”€â”€ ğŸ¤– GNN Model
â”‚   â”œâ”€â”€ supervised_trust_gnn.py          # Supervised GNN model & predictor
â”‚   â””â”€â”€ train_supervised_trust.py        # Training script
â”‚
â”œâ”€â”€ ğŸ“Š Dataset Generation
â”‚   â”œâ”€â”€ generate_supervised_data.py      # Generate training data
â”‚   â””â”€â”€ curriculum_learning.py           # Difficulty-based curriculum
â”‚
â”œâ”€â”€ ğŸ¯ Evaluation
â”‚   â”œâ”€â”€ compare_trust_methods.py         # Compare Paper vs Supervised
â”‚   â””â”€â”€ comprehensive_trust_benchmark.py # Extended benchmarking
â”‚
â”œâ”€â”€ ğŸŒ Simulation
â”‚   â”œâ”€â”€ simulation_environment.py        # Multi-robot simulation
â”‚   â”œâ”€â”€ robot_track_classes.py           # Robot/Track classes
â”‚   â””â”€â”€ paper_trust_algorithm.py         # Paper algorithm baseline
â”‚
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md                        # This file
    â”œâ”€â”€ COMPREHENSIVE_BENCHMARK_UPDATE.md
    â””â”€â”€ CROSS_VALIDATION_FILTERS_VERIFICATION.md
```

### Key Files Explained

**supervised_trust_gnn.py**:
- `SupervisedTrustGNN`: The GNN model class
- `TripletEncoder`: Transformer for symbolic structure encoding
- `SupervisedTrustPredictor`: Inference wrapper with cross-validation

**generate_supervised_data.py**:
- Simulates 15,000+ episodes with diverse parameters
- Builds ego-graphs for all robots at sampled timesteps
- Applies cross-validation filtering
- Outputs: `supervised_trust_dataset.pkl`

**train_supervised_trust.py**:
- Loads dataset and splits train/val (80/20)
- Trains with PyG batching (default, 2-3Ã— faster)
- Applies early stopping and learning rate scheduling
- Outputs: `supervised_trust_model.pth`

**compare_trust_methods.py**:
- Runs 3 test scenarios with identical random seeds
- Compares Paper Algorithm vs Supervised GNN
- Generates comparison plots and metrics
- Outputs: JSON results + PNG visualizations

---

## ğŸ”§ Advanced Usage

### Custom Training Configuration

```bash
# High-capacity model for large datasets
python train_supervised_trust.py \
  --data supervised_trust_dataset.pkl \
  --hidden-dim 256 \
  --num-layers 4 \
  --dropout 0.2 \
  --batch-size 64 \
  --lr 5e-4 \
  --epochs 2000

# Fast training (lower accuracy)
python train_supervised_trust.py \
  --data supervised_trust_dataset.pkl \
  --hidden-dim 64 \
  --num-layers 2 \
  --batch-size 128 \
  --epochs 200
```

### Using the Trained Model

```python
from supervised_trust_gnn import SupervisedTrustPredictor

# Initialize predictor
predictor = SupervisedTrustPredictor(
    model_path='supervised_trust_model.pth',
    device='cpu',
    proximal_range=50.0
)

# During simulation
for timestep in range(num_timesteps):
    for robot in robots:
        # Get predictions
        result = predictor.predict_from_robots_tracks(
            ego_robot=robot,
            all_robots=robots,
            threshold=0.5
        )

        # Check cross-validation
        if result is None:
            continue  # Not enough evidence

        # Extract predictions
        predictions = result['predictions']

        # Update ego robot trust
        ego_trust = predictions['agent']['probabilities'][0][0]
        robot.update_trust_from_evidence(ego_trust)

        # Update track trust
        for track_idx in result['meaningful_track_indices']:
            track_trust = predictions['track']['probabilities'][track_idx][0]
            track.update_trust_from_evidence(track_trust)
```

### Comprehensive Benchmarking

```bash
# Run extensive benchmarks (40 scenarios: 10 in-distribution + 30 OOD)
python comprehensive_trust_benchmark.py \
  --output-dir comprehensive_benchmark \
  --supervised-model supervised_trust_model.pth \
  --threshold 0.5

# Output: Metrics, plots, and per-scenario results
```

---

## ğŸ§ª Testing & Validation

### Test Suite

```bash
# Test GNN model structure
python test_supervised_trust.py

# Test PyG batching correctness
python test_pyg_batching.py

# Test cross-validation filters
python test_cross_validation_filters.py

# Test adversarial ratio changes
python test_adversarial_ratio_changes.py
```

### Validation Metrics

**During Training:**
- Classification accuracy (agents & tracks)
- F1 score
- Precision & Recall
- Loss convergence

**During Evaluation:**
- Trust separation (legitimate vs adversarial)
- Convergence speed
- False positive rate (good robots flagged as bad)
- True positive rate (bad robots correctly identified)

---

## ğŸ› Troubleshooting

### Common Issues

#### Issue 1: Low Training Accuracy (<80%)

**Symptoms:**
- Both train and val accuracy below 80%
- Model not learning

**Solutions:**
- âœ… Generate more diverse data (increase episodes to 20,000+)
- âœ… Check label balance (should be ~50/50 adversarial vs legitimate)
- âœ… Increase model capacity (hidden_dim 128 â†’ 256)
- âœ… Verify edge types exist in dataset (print edge_index_dict)

#### Issue 2: Overfitting (Train good, Val bad)

**Symptoms:**
- Train accuracy >90%, Val accuracy <75%
- Val loss increasing while train loss decreasing

**Solutions:**
- âœ… Increase dropout (0.1 â†’ 0.3)
- âœ… Increase weight decay (1e-4 â†’ 1e-3)
- âœ… Generate more data for better generalization
- âœ… Reduce model size (hidden_dim 256 â†’ 128)

#### Issue 3: Slow Trust Convergence

**Symptoms:**
- Takes >150 timesteps for trust to stabilize
- Trust values hover around 0.5

**Solutions:**
- âœ… Check GNN evidence scores (should be <0.3 or >0.7, not ~0.5)
- âœ… Verify cross-validation constraints are being met
- âœ… Check that contradicts edges are being created correctly
- âœ… Increase confidence in trust updates

#### Issue 4: CUDA Out of Memory

**Symptoms:**
- Training crashes with "CUDA out of memory" error

**Solutions:**
- âœ… Reduce batch size (32 â†’ 16 or 8)
- âœ… Use gradient accumulation
- âœ… Reduce hidden dimension (256 â†’ 128)
- âœ… Train on CPU (slower but works): `--device cpu`

---

## ğŸ“š Background & Motivation

### Why Graph Neural Networks?

**Traditional Approaches:**
- Use numerical features (positions, velocities, sensor readings)
- Require domain knowledge for feature engineering
- Sensitive to scale and units

**Our GNN Approach:**
- Uses **only graph structure** (who observes what, who agrees/disagrees)
- No handcrafted features
- Learns patterns automatically from data
- Privacy-preserving (no sensitive numerical data)

### Why Cross-Validation Constraints?

**Without Cross-Validation:**
- Single robot can manipulate trust easily
- No way to verify contradictory claims
- Vulnerable to coordinated attacks

**With Cross-Validation:**
- Requires multiple independent observations
- Contradictions become visible
- Harder for adversaries to coordinate deception
- More robust and reliable trust updates

### Why Compare with Paper Algorithm?

**Scientific Rigor:**
- Need baseline to measure improvement
- Paper algorithm represents state-of-the-art symbolic approach
- Fair comparison: both use same simulation, same data

**Practical Insight:**
- Shows when learning-based methods help
- Identifies scenarios where simple rules work well
- Guides deployment decisions

---

## ğŸ¯ Key Takeaways

### What Makes This System Special

1. **Structure-Only Learning**: No positions, velocities, or sensors - just graph topology
2. **Cross-Validation**: Built-in robustness through multi-robot consensus
3. **Ego-Centric**: Scalable and distributed architecture
4. **Symbolic Encoding**: Transformer-based triplet encoding for meaningful initialization
5. **Comprehensive Comparison**: Rigorous evaluation against symbolic baseline

### When to Use This System

**Best For:**
- Multi-robot teams with potential adversaries
- Privacy-sensitive applications
- Dynamic environments
- Scenarios where robots must learn to trust

**Not Ideal For:**
- Single robot systems
- Fully cooperative teams (no adversaries)
- Applications requiring perfect accuracy (99.9%+)
- Real-time constraints (<1ms latency)

### Performance Summary

**Supervised GNN:**
- âœ… 90%+ classification accuracy on validation set
- âœ… 0.521 trust gap between legitimate and adversarial
- âœ… Works across diverse scenarios (different FP/FN rates)
- âœ… Better adversarial detection than paper algorithm

**Paper Algorithm:**
- âœ… Interpretable and transparent
- âœ… No training required
- âœ… Fast inference
- âš ï¸ Lower adversarial detection (0.298 trust gap)

---

## ğŸ¤ Contributing

We welcome contributions! Areas where help is needed:

- ğŸ§ª **Testing**: More test scenarios and edge cases
- ğŸ“Š **Evaluation**: Additional metrics and visualizations
- ğŸ—ï¸ **Architecture**: Model improvements and optimizations
- ğŸ“š **Documentation**: Tutorials and examples
- ğŸ› **Bug Fixes**: Improvements and fixes

---

## ğŸ“– Citation

If you use this code in your research, please cite:

```bibtex
@software{neural_symbolic_trust_2025,
  title = {Neural-Symbolic Multi-Robot Trust System},
  author = {Wang, Ruiyang and Contributors},
  year = {2025},
  url = {https://github.com/yourusername/neural-symbolic-trust},
  note = {Graph Neural Network for distributed trust assessment
          with cross-validation constraints}
}
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

---

## ğŸ™ Acknowledgments

- **PyTorch Geometric Team**: For the excellent heterogeneous GNN framework
- **PyTorch Team**: For the deep learning infrastructure
- **Research Community**: For feedback and insights on trust modeling

---

## ğŸ“ Contact

For questions, issues, or collaboration:
- ğŸ“§ Email: your.email@university.edu
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/neural-symbolic-trust/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/neural-symbolic-trust/discussions)

---

**Built with â¤ï¸ and PyTorch**

*Making multi-robot teams safer and more reliable through learned trust.*
